# å¦‚æœè¿˜æ²¡æœ‰å®‰è£…ç›¸å…³ä¾èµ–ï¼Œå¯ä»¥å…ˆæ‰§è¡Œä¸‹é¢çš„å®‰è£…å‘½ä»¤ï¼ˆåªéœ€æ‰§è¡Œä¸€æ¬¡ï¼‰
# !pip install sentence-transformers huggingface_hub transformers

import json
import torch
import os
from sentence_transformers import SentenceTransformer, util
from huggingface_hub import hf_hub_download

# âœ… æ˜¯å¦å¯ç”¨æƒ…ç»ªè¾…åŠ©åŠŸèƒ½ï¼ˆè®¾ç½®ä¸º False å¯ç¦ç”¨ï¼‰
USE_EMOTION_ASSIST = True

# ------------------------------
# å®šä¹‰ DenseRetrievalExactSearch ç±»ï¼ˆæ”¯æŒå‘é‡å­˜å‚¨ï¼‰
# ------------------------------
class DenseRetrievalExactSearch:
    def __init__(self, text_embedding_model, batch_size=32, corpus_size=None, save_path="corpus_data"):
        """
        text_embedding_model: SentenceTransformer æ¨¡å‹
        batch_size: æ‰¹é‡è®¡ç®—å¤§å°
        corpus_size: é™åˆ¶ç´¢å¼•æ–‡æ¡£æ•°é‡ï¼ˆç”¨äºæµ‹è¯•ï¼‰
        save_path: å­˜å‚¨åµŒå…¥å‘é‡çš„æ–‡ä»¶å¤¹
        """
        self.model = text_embedding_model
        self.batch_size = batch_size
        self.corpus_size = corpus_size
        self.corpus_embeddings = None
        self.doc_ids = None
        self.save_path = save_path
        os.makedirs(save_path, exist_ok=True)  # ç¡®ä¿ç›®å½•å­˜åœ¨

    def index_corpus(self, corpus):
        """
        corpus: å­—å…¸ï¼Œæ ¼å¼ { doc_id: { "title": æ–‡æœ¬ } }
        """
        self.doc_ids = list(corpus.keys())
        docs = [corpus[doc_id]["title"] for doc_id in self.doc_ids]

        # é™åˆ¶ corpus_size
        if self.corpus_size is not None:
            docs = docs[:self.corpus_size]
            self.doc_ids = self.doc_ids[:self.corpus_size]

        # **æ£€æŸ¥æ˜¯å¦å·²å­˜å‚¨åµŒå…¥**
        emb_path = os.path.join(self.save_path, "corpus_embeddings.pt")
        doc_path = os.path.join(self.save_path, "corpus_doc_ids.json")

        if os.path.exists(emb_path) and os.path.exists(doc_path):
            print("âœ… åŠ è½½å·²å­˜å‚¨çš„åµŒå…¥å‘é‡...")
            self.corpus_embeddings = torch.load(emb_path)
            with open(doc_path, "r") as f:
                self.doc_ids = json.load(f)
            print(f"âœ… åŠ è½½å®Œæˆ: {len(self.doc_ids)} æ–‡æ¡£")
            return

        # **åµŒå…¥æœªå­˜å‚¨ï¼Œè®¡ç®—åµŒå…¥**
        print("ğŸ”„ è®¡ç®—æ–‡æ¡£åµŒå…¥...")
        batch_size = self.batch_size
        all_embeddings = []
        for i in range(0, len(docs), batch_size):
            batch_docs = docs[i : i + batch_size]
            batch_embeddings = self.model.encode(batch_docs, convert_to_tensor=True)
            all_embeddings.append(batch_embeddings)

        # **åˆå¹¶æ‰€æœ‰æ‰¹æ¬¡**
        self.corpus_embeddings = torch.cat(all_embeddings, dim=0)
        print(f"âœ… æ–‡æ¡£åµŒå…¥è®¡ç®—å®Œæˆ: {len(self.doc_ids)} æ–‡æ¡£")

        # **å­˜å‚¨åˆ°ç£ç›˜**
        torch.save(self.corpus_embeddings, emb_path)
        with open(doc_path, "w") as f:
            json.dump(self.doc_ids, f)
        print("âœ… åµŒå…¥å‘é‡å·²ä¿å­˜ï¼Œä¸‹æ¬¡å¯ç›´æ¥åŠ è½½ï¼")

    def search(self, corpus, queries, top_k=5, score_function='dot', return_sorted=True):
        """
        corpus: { doc_id: { "title": æ–‡æœ¬ } }
        queries: { query_id: æŸ¥è¯¢æ–‡æœ¬ }
        top_k: è¿”å›å‰ k ä¸ªç›¸ä¼¼æ–‡æ¡£
        score_function: 'cos_sim' æˆ– 'dot'
        """
        # **ç¡®ä¿å·²åŠ è½½åµŒå…¥**
        if self.corpus_embeddings is None:
            self.index_corpus(corpus)

        # **è®¡ç®—æŸ¥è¯¢å‘é‡**
        query_ids = list(queries.keys())
        query_texts = [queries[qid] for qid in query_ids]
        query_embeddings = self.model.encode(query_texts, batch_size=self.batch_size, convert_to_tensor=True)

        # **è®¡ç®—ç›¸ä¼¼åº¦**
        if score_function == 'cos_sim':
            sim_matrix = util.cos_sim(query_embeddings, self.corpus_embeddings)
        elif score_function == 'dot':
            sim_matrix = torch.matmul(query_embeddings, self.corpus_embeddings.T)
        else:
            raise ValueError(f"âŒ ä¸æ”¯æŒçš„ score_function: {score_function}")

        # **è·å– top-k ç»“æœ**
        results = {}
        for i, qid in enumerate(query_ids):
            sims = sim_matrix[i]
            top_results = torch.topk(sims, k=top_k)
            top_indices = top_results.indices
            top_scores = top_results.values

            result = {self.doc_ids[idx]: score.item() for idx, score in zip(top_indices, top_scores)}
            results[qid] = result

        return results


# ------------------------------
# ä¸‹è½½å¹¶åŠ è½½è¯­æ–™ï¼ˆcorpus.jsonlï¼‰
# è¿™é‡Œå‡è®¾ä½ çš„è¯­æ–™ä¸Šä¼ åœ¨ Hugging Face çš„ä»“åº“ "COMP631GroupSYCZ/Corpus"ï¼Œæ–‡ä»¶åä¸º "corpus.jsonl"
# ------------------------------
print("Downloading corpus from Hugging Face ...")
corpus_path = hf_hub_download(repo_id="COMP631GroupSYCZ/Corpus",
                              filename="corpus.jsonl",
                              repo_type="dataset")
print("Corpus downloaded:", corpus_path)

# è¯»å– JSONL æ–‡ä»¶ï¼Œæ¯è¡Œè§£æä¸ºä¸€ä¸ª JSON å¯¹è±¡ï¼Œå¹¶æ„é€ æˆ { doc_id: {"title": æ–‡æœ¬ } } çš„æ ¼å¼
corpus = {}
with open(corpus_path, 'r', encoding='utf-8') as f:
    for line in f:
        if line.strip():
            doc = json.loads(line)
            doc_id = doc["_id"]
            corpus[doc_id] = {"title": doc["title"]}

print("Total documents loaded:", len(corpus))

# # æ‰“å° corpus æœ€å 7 æ¡æ•°æ®çš„ ID å’Œæ ‡é¢˜
# for doc_id in list(corpus.keys())[-7:]:
#     print(f"ID: {doc_id}")
#     print(f"Title: {corpus[doc_id].get('title', 'No title')}\n")

# ------------------------------
# åŠ è½½æ–‡æœ¬åµŒå…¥æ¨¡å‹
# ------------------------------
print("Loading text embedding model ...")
model = SentenceTransformer("Lajavaness/bilingual-embedding-small", trust_remote_code=True)
print("Model loaded.")

# âœ… å¦‚æœå¯ç”¨æƒ…ç»ªè¾…åŠ©ï¼Œåˆ™åŠ è½½æƒ…ç»ªè¯†åˆ«æ¨¡å‹
if USE_EMOTION_ASSIST:
    from transformers import pipeline
    emotion_model = pipeline("text-classification", model="nateraw/bert-base-uncased-emotion", return_all_scores=True)
    print("Emotion model loaded.\n")

# ------------------------------
# åˆå§‹åŒ–ä¸‰ä¸ª Retriever
# ------------------------------
corpus_sci = {}
corpus_folk = {}
corpus_freud = {}

for doc_id, content in corpus.items():
    if doc_id.startswith("PMC"):
        corpus_sci[doc_id] = content
    elif doc_id.startswith("doc3_"):
        corpus_freud[doc_id] = content
    elif doc_id.isdigit():
        corpus_folk[doc_id] = content

print(f"âœ… ç§‘å­¦æ–‡çŒ®æ•°é‡: {len(corpus_sci)}")
print(f"âœ… å‘¨å…¬è§£æ¢¦æ•°é‡: {len(corpus_folk)}")
print(f"âœ… å¼—æ´›ä¼Šå¾·å†…å®¹æ•°é‡: {len(corpus_freud)}\n")

retriever_sci = DenseRetrievalExactSearch(model, save_path="retriever_sci")
retriever_folk = DenseRetrievalExactSearch(model, save_path="retriever_folk")
retriever_freud = DenseRetrievalExactSearch(model, save_path="retriever_freud")

retriever_sci.index_corpus(corpus_sci)
retriever_folk.index_corpus(corpus_folk)
retriever_freud.index_corpus(corpus_freud)


# ------------------------------
# å®šä¹‰æƒ…ç»ª+è¯­ä¹‰èåˆæ£€ç´¢çš„å‡½æ•°
# ------------------------------
def hybrid_emotion_search(dream_text, top_k=5, alpha=0.7):
    """
    å°†dream_textä¸æå–åˆ°çš„æƒ…ç»ªæ ‡ç­¾ä¸€èµ·ï¼Œç”¨åŠ æƒå‘é‡èåˆæ£€ç´¢corpus_sciã€‚
    """
    # 1. åŸå§‹æ¢¦å¢ƒå‘é‡
    v_semantic = model.encode(dream_text, convert_to_tensor=True)

    # 2. æƒ…ç»ªæ ‡ç­¾
    emotion_results = emotion_model(dream_text)[0]  # list of dict: {'label':..., 'score':...}
    top_tags = [r['label'] for r in sorted(emotion_results, key=lambda x: x['score'], reverse=True)[:2]]
    # æ„é€ ä¸€ä¸ªæƒ…ç»ªæŸ¥è¯¢å­—ç¬¦ä¸²
    emotion_query = "dream, " + ", ".join(top_tags)
    v_emotion = model.encode(emotion_query, convert_to_tensor=True)

    # 3. å‘é‡èåˆ
    v_query = alpha * v_semantic + (1 - alpha) * v_emotion

    # 4. å’Œç§‘å­¦æ–‡çŒ® embeddings åšcosineç›¸ä¼¼åº¦
    sim_matrix = util.cos_sim(v_query, retriever_sci.corpus_embeddings)[0]
    top_indices = torch.topk(sim_matrix, k=top_k).indices

    # 5. ç”Ÿæˆç»“æœ
    results = {}
    for i in top_indices:
        doc_id = retriever_sci.doc_ids[i]
        results[doc_id] = sim_matrix[i].item()

    return results, top_tags


# ------------------------------
# ç°åœ¨å‡†å¤‡æŸ¥è¯¢
# ------------------------------
user_query = {
    "q1": "æˆ‘æ˜¨æ™šæ¢¦è§é£ç¿”çš„é±¼å’Œå¥‡æ€ªçš„å»ºç­‘",
    "q2": "Freudian dream analysis about symbols and hidden desires",  # ç¤ºä¾‹è‹±æ–‡æŸ¥è¯¢
    "q3": "I was surrounded by a mass of people, some of whom I knew and some I didn't know. The dream continued like that for what seemed to be a long time. The people were not talking or moving. They were just existing. I was not talking or moving. We were all just standing there. The background was just all darkness with, no dimension. It was as if we were floating on nothing, existing nowhere. The people were of every race, sex and age. Then, after a while, everyone, but me, just fell in the darkness, tumbling down until they became very small, then they disappeared. They did not scream or make any noise. I was left alone, but did not wonder where everyone left, until I woke up a few minutes later. I don't recall having any feelings during the dream. The dream was not pleasant or unpleasant. It kind if just happened. (153 words)",
    "q4": "I felt scared. I was pregnant in my dream. Then the dream jumped to my boyfriend and we're having sex together when his parents come home early from their vacation and caught us. I started to cry and his mom comforted me. She kept saying It's OK sweetheart. His father took him aside and talked with him. I was so embarrassed. What would they think of me now? Would they hate me? They loved me once. In real life I know this would never have happened. His parents would kill us instead.",
    "q5": "I feel anxiety, what should I do",
}

if USE_EMOTION_ASSIST:
    # âœ… ä½¿ç”¨æƒ…ç»ªè¾…åŠ©+è¯­ä¹‰èåˆæ£€ç´¢
    results_sci = {}
    for qid, text in user_query.items():
        r, tags = hybrid_emotion_search(text, top_k=3, alpha=0.7)
        results_sci[qid] = r
        print(f"ã€æƒ…ç»ªè¾…åŠ©ã€‘Query: {text}")
        print(f"Detected Emotions: {tags}\n")
else:
    # âŒ ä¸ä½¿ç”¨æƒ…ç»ªè¾…åŠ©æ—¶ï¼ŒåŸç”Ÿæ£€ç´¢
    results_sci = retriever_sci.search(corpus_sci, user_query, top_k=3, score_function='cos_sim')

# å‘¨å…¬è§£æ¢¦å’Œå¼—æ´›ä¼Šå¾·ä¾æ—§ä½¿ç”¨æ™®é€šæ£€ç´¢
results_folk = retriever_folk.search(corpus_folk, user_query, top_k=3, score_function='cos_sim')
results_freud = retriever_freud.search(corpus_freud, user_query, top_k=3, score_function='cos_sim')


# ------------------------------
# æ‰“å°æŸ¥è¯¢ç»“æœ
# ------------------------------
def print_query_results(user_query, sci_results, folk_results, freud_results, corpus_sci, corpus_folk, corpus_freud):
    print("ğŸ’¤ ç”¨æˆ·è¾“å…¥æ¢¦å¢ƒï¼š", user_query["q3"])
    print("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("ğŸ”® ã€æ°‘ä¿—è§£è¯»ã€‘")
    folk = folk_results.get("q3", {})
    if folk:
        for doc_id, score in folk.items():
            title = corpus_folk[doc_id].get("title", "")[:80]
            print(f"ğŸ”¸ {title} (Score: {score:.4f})")
    else:
        print("âš ï¸ æš‚æ— ç›¸å…³çš„å‘¨å…¬è§£æ¢¦åŒ¹é…ç»“æœ")
    print()

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("ğŸ§  ã€ç²¾ç¥åˆ†æè§†è§’ã€‘")
    freud = freud_results.get("q3", {})
    if freud:
        for doc_id, score in freud.items():
            title = corpus_freud[doc_id].get("title", "")[:80]
            print(f"ğŸ”¹ {title} (Score: {score:.4f})")
    else:
        print("âš ï¸ æš‚æ— å¼—æ´›ä¼Šå¾·ç†è®ºç›¸å…³è§£é‡Š")
    print()

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("ğŸ”¬ ã€ç§‘å­¦è§£é‡Šã€‘")
    sci = sci_results.get("q3", {})
    if sci:
        for doc_id, score in sci.items():
            title = corpus_sci[doc_id].get("title", "")[:80]
            print(f"ğŸ”¬ {title} (Score: {score:.4f})")
    else:
        print("âš ï¸ æœªæ‰¾åˆ°åŒ¹é…çš„å¿ƒç†å­¦ç ”ç©¶æ–‡çŒ®")
    print()

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("ğŸ“ ã€æƒ…ç»ªåˆ†æä¸å»ºè®®ã€‘ï¼ˆå¯åœ¨æ­¤å¤„æ·»åŠ æ›´å¤šåŸºäºæƒ…ç»ªçš„ä¸ªæ€§åŒ–å»ºè®®ï¼‰")
    print("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n")

print_query_results(user_query, results_sci, results_folk, results_freud, corpus_sci, corpus_folk, corpus_freud)
